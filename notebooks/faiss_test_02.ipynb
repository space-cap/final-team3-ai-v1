{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8540d31f",
   "metadata": {},
   "source": [
    "# Python FAISS를 활용한 문서 유사도 검색 예제\n",
    "\n",
    "다음은 FAISS를 사용하여 문서에서 유사도를 찾는 실제 예제를 단계별로 보여드리겠습니다:[1][2]\n",
    "\n",
    "## 기본 설치 및 라이브러리 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11168741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdf9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS 설치 (사전 준비)\n",
    "# pip install faiss-cpu\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer  # 더 나은 임베딩을 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20905786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 차원: 30\n"
     ]
    }
   ],
   "source": [
    "# 예시 문서 데이터\n",
    "documents = [\n",
    "    \"파이썬은 프로그래밍 언어입니다. 배우기 쉽고 강력합니다.\",\n",
    "    \"머신러닝은 인공지능의 한 분야입니다. 데이터로부터 학습합니다.\",\n",
    "    \"FAISS는 벡터 유사도 검색 라이브러리입니다. 페이스북에서 개발했습니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하는 기술입니다.\",\n",
    "    \"딥러닝은 신경망을 사용한 머신러닝 기법입니다.\",\n",
    "]\n",
    "\n",
    "# 문서에 대한 ID 설정\n",
    "doc_ids = np.array([101, 102, 103, 104, 105], dtype=\"int64\")\n",
    "\n",
    "# 간단한 TF-IDF 벡터화 (실제로는 Sentence-BERT 등 사용 권장)\n",
    "vectorizer = TfidfVectorizer(max_features=512)\n",
    "doc_vectors = vectorizer.fit_transform(documents).toarray().astype(\"float32\")\n",
    "\n",
    "# 벡터 차원 확인\n",
    "d = doc_vectors.shape[1]\n",
    "print(f\"벡터 차원: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3ec27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스에 추가된 문서 수: 5\n"
     ]
    }
   ],
   "source": [
    "# FAISS 인덱스 생성\n",
    "index = faiss.IndexFlatL2(d)  # L2 거리 기반\n",
    "index = faiss.IndexIDMap2(index)  # ID 매핑 기능 추가\n",
    "\n",
    "# 문서 벡터와 ID를 인덱스에 추가\n",
    "index.add_with_ids(doc_vectors, doc_ids)\n",
    "\n",
    "print(f\"인덱스에 추가된 문서 수: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851ad21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 결과:\n",
      "순위 1: 문서 ID 102, 거리: 1.0000\n",
      "문서 내용: 머신러닝은 인공지능의 한 분야입니다. 데이터로부터 학습합니다.\n",
      "--------------------------------------------------\n",
      "순위 2: 문서 ID 103, 거리: 1.0000\n",
      "문서 내용: FAISS는 벡터 유사도 검색 라이브러리입니다. 페이스북에서 개발했습니다.\n",
      "--------------------------------------------------\n",
      "순위 3: 문서 ID 104, 거리: 1.0000\n",
      "문서 내용: 자연어 처리는 컴퓨터가 인간의 언어를 이해하는 기술입니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 검색 쿼리\n",
    "query_text = \"인공지능 기계학습에 대해 알고 싶습니다\"\n",
    "\n",
    "# 쿼리를 벡터로 변환\n",
    "query_vector = vectorizer.transform([query_text]).toarray().astype(\"float32\")\n",
    "\n",
    "# 유사한 문서 3개 검색\n",
    "k = 3\n",
    "distances, indices = index.search(query_vector, k)\n",
    "\n",
    "print(\"검색 결과:\")\n",
    "for i in range(k):\n",
    "    doc_id = indices[0][i]\n",
    "    distance = distances[0][i]\n",
    "    print(f\"순위 {i+1}: 문서 ID {doc_id}, 거리: {distance:.4f}\")\n",
    "    print(f\"문서 내용: {documents[doc_id - 101]}\")  # ID를 배열 인덱스로 변환\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbbaed0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "코사인 유사도 검색 결과:\n",
      "순위 1: 문서 ID 103, 유사도: 0.0000\n",
      "문서 내용: FAISS는 벡터 유사도 검색 라이브러리입니다. 페이스북에서 개발했습니다.\n",
      "--------------------------------------------------\n",
      "순위 2: 문서 ID 102, 유사도: 0.0000\n",
      "문서 내용: 머신러닝은 인공지능의 한 분야입니다. 데이터로부터 학습합니다.\n",
      "--------------------------------------------------\n",
      "순위 3: 문서 ID 101, 유사도: 0.0000\n",
      "문서 내용: 파이썬은 프로그래밍 언어입니다. 배우기 쉽고 강력합니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 코사인 유사도를 위해 벡터 정규화\n",
    "def normalize_vectors(vectors):\n",
    "    \"\"\"벡터를 L2 정규화하여 코사인 유사도 계산 가능하게 함\"\"\"\n",
    "    faiss.normalize_L2(vectors)\n",
    "    return vectors\n",
    "\n",
    "\n",
    "# 정규화된 벡터로 인덱스 재생성\n",
    "normalized_vectors = doc_vectors.copy()\n",
    "normalize_vectors(normalized_vectors)\n",
    "\n",
    "# 정규화된 인덱스 생성\n",
    "normalized_index = faiss.IndexFlatIP(d)  # 내적 사용 (정규화된 벡터에서는 코사인 유사도)\n",
    "normalized_index = faiss.IndexIDMap2(normalized_index)\n",
    "normalized_index.add_with_ids(normalized_vectors, doc_ids)\n",
    "\n",
    "# 쿼리 벡터도 정규화\n",
    "query_normalized = query_vector.copy()\n",
    "normalize_vectors(query_normalized)\n",
    "\n",
    "# 코사인 유사도 검색\n",
    "distances, indices = normalized_index.search(query_normalized, k)\n",
    "\n",
    "print(\"\\n코사인 유사도 검색 결과:\")\n",
    "for i in range(k):\n",
    "    doc_id = indices[0][i]\n",
    "    similarity = distances[0][i]  # 내적 값 (코사인 유사도)\n",
    "    print(f\"순위 {i+1}: 문서 ID {doc_id}, 유사도: {similarity:.4f}\")\n",
    "    print(f\"문서 내용: {documents[doc_id - 101]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d602de90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence-BERT 임베딩 검색 결과:\n",
      "순위 1: 문서 ID 102, 거리: 4.3968\n",
      "문서 내용: 머신러닝은 인공지능의 한 분야입니다. 데이터로부터 학습합니다.\n",
      "--------------------------------------------------\n",
      "순위 2: 문서 ID 105, 거리: 10.3969\n",
      "문서 내용: 딥러닝은 신경망을 사용한 머신러닝 기법입니다.\n",
      "--------------------------------------------------\n",
      "순위 3: 문서 ID 103, 거리: 13.0032\n",
      "문서 내용: FAISS는 벡터 유사도 검색 라이브러리입니다. 페이스북에서 개발했습니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sentence-BERT 모델 사용 (더 정확한 의미론적 임베딩)\n",
    "# pip install sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 모델 로드\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "# 문서들을 임베딩으로 변환\n",
    "doc_embeddings = model.encode(documents, convert_to_tensor=False)\n",
    "doc_embeddings = doc_embeddings.astype(\"float32\")\n",
    "\n",
    "# 새로운 차원으로 인덱스 재생성\n",
    "d_bert = doc_embeddings.shape[1]\n",
    "bert_index = faiss.IndexFlatL2(d_bert)\n",
    "bert_index = faiss.IndexIDMap2(bert_index)\n",
    "bert_index.add_with_ids(doc_embeddings, doc_ids)\n",
    "\n",
    "# 쿼리 임베딩 생성\n",
    "query_embedding = model.encode([query_text], convert_to_tensor=False).astype(\"float32\")\n",
    "\n",
    "# 검색 수행\n",
    "distances, indices = bert_index.search(query_embedding, k)\n",
    "\n",
    "print(\"\\nSentence-BERT 임베딩 검색 결과:\")\n",
    "for i in range(k):\n",
    "    doc_id = indices[0][i]\n",
    "    distance = distances[0][i]\n",
    "    print(f\"순위 {i+1}: 문서 ID {doc_id}, 거리: {distance:.4f}\")\n",
    "    print(f\"문서 내용: {documents[doc_id - 101]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "813fa2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스가 저장되었습니다.\n",
      "\n",
      "로드된 인덱스 검색 결과: 문서 ID [102 105]\n"
     ]
    }
   ],
   "source": [
    "# 인덱스 저장\n",
    "faiss.write_index(bert_index, \"document_similarity_index.faiss\")\n",
    "print(\"인덱스가 저장되었습니다.\")\n",
    "\n",
    "# 저장된 인덱스 로드\n",
    "loaded_index = faiss.read_index(\"document_similarity_index.faiss\")\n",
    "\n",
    "# 로드된 인덱스로 검색 테스트\n",
    "test_distances, test_indices = loaded_index.search(query_embedding, 2)\n",
    "print(f\"\\n로드된 인덱스 검색 결과: 문서 ID {test_indices[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce11e173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 ID 103의 벡터 차원: (384,)\n",
      "원본 문서: FAISS는 벡터 유사도 검색 라이브러리입니다. 페이스북에서 개발했습니다.\n",
      "벡터 복원 성공: True\n"
     ]
    }
   ],
   "source": [
    "# 특정 ID의 벡터 복원\n",
    "target_id = 103\n",
    "reconstructed_vector = bert_index.reconstruct(target_id)\n",
    "\n",
    "print(f\"문서 ID {target_id}의 벡터 차원: {reconstructed_vector.shape}\")\n",
    "print(f\"원본 문서: {documents[target_id - 101]}\")\n",
    "\n",
    "# 복원된 벡터가 원본과 동일한지 확인\n",
    "original_vector = doc_embeddings[target_id - 101]\n",
    "is_same = np.allclose(reconstructed_vector, original_vector)\n",
    "print(f\"벡터 복원 성공: {is_same}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1656be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
